<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.335">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>comparación_de_modelos</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation docked overflow-auto">
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        <div class="sidebar-tools-collapse">
    <a href="" title="" id="sidebar-tool-dropdown-0" class="sidebar-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi bi-github"></i></a>
    <ul class="dropdown-menu" aria-labelledby="sidebar-tool-dropdown-0">
        <li>
          <a class="dropdown-item sidebar-tools-collapse-item" href="https://github.com/Grupo-de-modelado-probabilista/Modelado_Bayesiano">
          Fuente
          </a>
        </li>
        <li>
          <a class="dropdown-item sidebar-tools-collapse-item" href="https://github.com/Grupo-de-modelado-probabilista/Modelado_Bayesiano/issues/new">
          Reportar errores
          </a>
        </li>
    </ul>
</div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">home</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Introducción al modelado, inferencia y análisis de modelos Bayesianos</a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">Capítulo 0</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./00_Probabilidad.html" class="sidebar-item-text sidebar-link">Probabilidad</a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">Capítulo 1</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01_Inferencia_Bayesiana.html" class="sidebar-item-text sidebar-link">Inferencia Bayesiana</a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">Capítulo 2</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02_Programación_probabilística.html" class="sidebar-item-text sidebar-link">Programación probabilista</a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">Capítulo 3</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03_Modelos_jerárquicos.html" class="sidebar-item-text sidebar-link">Modelado Jerárquico</a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true">Capítulo 4</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04_Diagnóstico_MCMC.html" class="sidebar-item-text sidebar-link">MCMC y diagnóstico del muestro</a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true">Capítulo 5</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05_Regresión_lineal.html" class="sidebar-item-text sidebar-link">Regresión Lineal</a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="true">Capítulo 6</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06_Generalizando_modelos_lineales.html" class="sidebar-item-text sidebar-link">Generalizando modelos lineales</a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" aria-expanded="true">Capítulo 7</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07_Comparación_de_modelos.html" class="sidebar-item-text sidebar-link active">Comparación de modelos</a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#comparación-de-modelos" id="toc-comparación-de-modelos" class="nav-link active" data-scroll-target="#comparación-de-modelos">Comparación de modelos</a>
  <ul class="collapse">
  <li><a href="#pruebas-predictivas-a-posteriori" id="toc-pruebas-predictivas-a-posteriori" class="nav-link" data-scroll-target="#pruebas-predictivas-a-posteriori">Pruebas predictivas a posteriori</a></li>
  </ul></li>
  <li><a href="#la-navaja-de-occam-simplicidad-y-exactitud" id="toc-la-navaja-de-occam-simplicidad-y-exactitud" class="nav-link" data-scroll-target="#la-navaja-de-occam-simplicidad-y-exactitud">La navaja de Occam: simplicidad y exactitud</a>
  <ul class="collapse">
  <li><a href="#muchos-parámetros-pueden-conducir-a-sobreajuste" id="toc-muchos-parámetros-pueden-conducir-a-sobreajuste" class="nav-link" data-scroll-target="#muchos-parámetros-pueden-conducir-a-sobreajuste">Muchos parámetros (pueden) conducir a sobreajuste</a></li>
  <li><a href="#muy-pocos-parámetros-conducen-a-un-subajuste" id="toc-muy-pocos-parámetros-conducen-a-un-subajuste" class="nav-link" data-scroll-target="#muy-pocos-parámetros-conducen-a-un-subajuste">Muy pocos parámetros conducen a un subajuste</a></li>
  <li><a href="#el-equilibrio-entre-simplicidad-y-exactitud" id="toc-el-equilibrio-entre-simplicidad-y-exactitud" class="nav-link" data-scroll-target="#el-equilibrio-entre-simplicidad-y-exactitud">El equilibrio entre simplicidad y exactitud</a></li>
  <li><a href="#medidas-de-exactitud-predictiva" id="toc-medidas-de-exactitud-predictiva" class="nav-link" data-scroll-target="#medidas-de-exactitud-predictiva">Medidas de exactitud predictiva</a>
  <ul class="collapse">
  <li><a href="#validación-cruzada" id="toc-validación-cruzada" class="nav-link" data-scroll-target="#validación-cruzada">Validación cruzada</a></li>
  <li><a href="#criterios-de-información" id="toc-criterios-de-información" class="nav-link" data-scroll-target="#criterios-de-información">Criterios de información</a></li>
  </ul></li>
  <li><a href="#calcular-los-criterios-de-información-con-arviz" id="toc-calcular-los-criterios-de-información-con-arviz" class="nav-link" data-scroll-target="#calcular-los-criterios-de-información-con-arviz">Calcular los criterios de información con ArviZ</a></li>
  <li><a href="#promedio-de-modelos" id="toc-promedio-de-modelos" class="nav-link" data-scroll-target="#promedio-de-modelos">Promedio de modelos</a></li>
  <li><a href="#factores-de-bayes" id="toc-factores-de-bayes" class="nav-link" data-scroll-target="#factores-de-bayes">Factores de Bayes</a></li>
  <li><a href="#algunas-observaciones" id="toc-algunas-observaciones" class="nav-link" data-scroll-target="#algunas-observaciones">Algunas observaciones</a></li>
  <li><a href="#cálculo-de-los-fb" id="toc-cálculo-de-los-fb" class="nav-link" data-scroll-target="#cálculo-de-los-fb">Cálculo de los FB</a>
  <ul class="collapse">
  <li><a href="#analiticamente" id="toc-analiticamente" class="nav-link" data-scroll-target="#analiticamente">Analiticamente</a></li>
  <li><a href="#sequential-monte-carlo" id="toc-sequential-monte-carlo" class="nav-link" data-scroll-target="#sequential-monte-carlo">Sequential Monte Carlo</a></li>
  </ul></li>
  <li><a href="#factores-de-bayes-e-inferencia" id="toc-factores-de-bayes-e-inferencia" class="nav-link" data-scroll-target="#factores-de-bayes-e-inferencia">Factores de bayes e inferencia</a></li>
  <li><a href="#cociente-de-savage-dickey" id="toc-cociente-de-savage-dickey" class="nav-link" data-scroll-target="#cociente-de-savage-dickey">Cociente de Savage-Dickey</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">



<section id="comparación-de-modelos" class="level1">
<h1>Comparación de modelos</h1>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> arviz <span class="im">as</span> az</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib.ticker <span class="im">import</span> FormatStrFormatter</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> preliz <span class="im">as</span> pz</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pymc <span class="im">as</span> pm</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.special <span class="im">import</span> betaln</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>az.style.use(<span class="st">'arviz-doc'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<blockquote class="blockquote">
<p>“Un mapa no es el territorio que representa, pero si es correcto, tiene una estructura similar a la del territorio” - Alfred Korzybski</p>
</blockquote>
<p>Todos los modelos son erróneos, en el sentido de que solo son aproximaciones que se utilizan para intentar comprender un problema a través de datos y no una copia literal del <em>mundo real</em>. Si bien todos los modelos son incorrectos, no todos los modelos son igualmente incorrectos; algunos modelos serán mejores que otros al describir los mismos datos, o incluso para cierto rangos o subconjuntos de los datos. En los capítulos anteriores, centramos nuestra atención en el problema de inferencia, es decir, cómo aprender el valor de los parámetros a partir de los datos. En este capítulo, nos centraremos en un problema complementario: cómo comparar dos o más modelos utilizados para explicar los mismos datos. Como veremos, este no es un problema trivial y, al mismo tiempo, es un problema central en el análisis de datos.</p>
<p>En el presente capítulo, exploraremos los siguientes temas:</p>
<ul>
<li>Overfitting y underfitting</li>
<li>Validación cruzada</li>
<li>Factores de Bayes</li>
<li>Regularización</li>
</ul>
<section id="pruebas-predictivas-a-posteriori" class="level2">
<h2 class="anchored" data-anchor-id="pruebas-predictivas-a-posteriori">Pruebas predictivas a posteriori</h2>
<p>Previamente hemos presentado y discutido las pruebas predictivas a posteriori como una forma de evaluar qué tan bien los modelos explican los mismos datos que se usan para ajustar al modelo. El propósito de este tipo de pruebas no es el de dictaminar que un modelo es incorrecto; ¡Esto ya lo sabemos! El objetivo del ejercicio es comprender qué tan bien estamos capturando los datos. Es frecuente que capturemos diferentes aspectos de los datos de diferentes maneras. Al realizar pruebas predictivas a posteriori, esperamos comprender mejor las limitaciones de un modelo, ya sea para tenerlas en cuenta o para intentar mejorar el modelo. Es esperable que un modelo no sea capaz de reproducir todos los aspectos de un problema y, por lo general, esto no es un problema ya que los modelos se construyen con un propósito en mente. Una prueba predictiva a posteriori es una forma de evaluar ese propósito, por lo tanto, si tenemos más de un modelo, podemos compararlos mediante pruebas predictivas a posteriori.</p>
<p>Como ya vimos, las pruebas predictivas a posteriori a menudo se realizan mediante visualizaciones como en el siguiente ejemplo:</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>dummy_data <span class="op">=</span> np.loadtxt(<span class="st">'datos/dummy.csv'</span>)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>x_1 <span class="op">=</span> dummy_data[:,<span class="dv">0</span>]</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>y_1 <span class="op">=</span> dummy_data[:,<span class="dv">1</span>]</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>order <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>x_1p <span class="op">=</span> np.vstack([x_1<span class="op">**</span>i <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, order<span class="op">+</span><span class="dv">1</span>)])</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>x_1s <span class="op">=</span> (x_1p <span class="op">-</span> x_1p.mean(axis<span class="op">=</span><span class="dv">1</span>, keepdims<span class="op">=</span><span class="va">True</span>)) <span class="op">/</span> x_1p.std(axis<span class="op">=</span><span class="dv">1</span>, keepdims<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>y_1s <span class="op">=</span> (y_1 <span class="op">-</span> y_1.mean()) <span class="op">/</span> y_1.std()</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>plt.scatter(x_1s[<span class="dv">0</span>], y_1s)</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'x'</span>)</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'y'</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="07_Comparación_de_modelos_files/figure-html/cell-4-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>Ahora, vamos a ajustar estos datos con dos modelos ligeramente diferentes, uno lineal y el otro un polinomio de orden 2, también conocido como modelo parabólico o cuadrático:</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> pm.Model() <span class="im">as</span> model_l:</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    α <span class="op">=</span> pm.Normal(<span class="st">'α'</span>, mu<span class="op">=</span><span class="dv">0</span>, sigma<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>    β <span class="op">=</span> pm.Normal(<span class="st">'β'</span>, mu<span class="op">=</span><span class="dv">0</span>, sigma<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>    ϵ <span class="op">=</span> pm.HalfNormal(<span class="st">'ϵ'</span>, <span class="dv">5</span>)</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>    μ <span class="op">=</span> α <span class="op">+</span> β <span class="op">*</span> x_1s[<span class="dv">0</span>]</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> pm.Normal(<span class="st">'y_pred'</span>, mu<span class="op">=</span>μ, sigma<span class="op">=</span>ϵ, observed<span class="op">=</span>y_1s)</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>    idata_l <span class="op">=</span> pm.sample(<span class="dv">2000</span>, idata_kwargs<span class="op">=</span>{<span class="st">"log_likelihood"</span>: <span class="va">True</span>})</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>    idata_l.extend(pm.sample_posterior_predictive(idata_l))</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> pm.Model() <span class="im">as</span> model_p:</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>    α <span class="op">=</span> pm.Normal(<span class="st">'α'</span>, mu<span class="op">=</span><span class="dv">0</span>, sigma<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>    β <span class="op">=</span> pm.Normal(<span class="st">'β'</span>, mu<span class="op">=</span><span class="dv">0</span>, sigma<span class="op">=</span><span class="dv">10</span>, shape<span class="op">=</span>order)</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>    ϵ <span class="op">=</span> pm.HalfNormal(<span class="st">'ϵ'</span>, <span class="dv">5</span>)</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>    μ <span class="op">=</span> α <span class="op">+</span> pm.math.dot(β, x_1s)</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> pm.Normal(<span class="st">'y_pred'</span>, mu<span class="op">=</span>μ, sigma<span class="op">=</span>ϵ, observed<span class="op">=</span>y_1s)</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>    idata_p <span class="op">=</span> pm.sample(<span class="dv">2000</span>, idata_kwargs<span class="op">=</span>{<span class="st">"log_likelihood"</span>: <span class="va">True</span>})</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>    idata_p.extend(pm.sample_posterior_predictive(idata_p))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [α, β, ϵ]</code></pre>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="12000" class="" max="12000" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [12000/12000 00:05&lt;00:00 Sampling 4 chains, 0 divergences]
    </div>
    
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Sampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 5 seconds.
Sampling: [y_pred]</code></pre>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="8000" class="" max="8000" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [8000/8000 00:00&lt;00:00]
    </div>
    
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [α, β, ϵ]</code></pre>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="12000" class="" max="12000" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [12000/12000 00:08&lt;00:00 Sampling 4 chains, 0 divergences]
    </div>
    
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Sampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 9 seconds.
Sampling: [y_pred]</code></pre>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="8000" class="" max="8000" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [8000/8000 00:00&lt;00:00]
    </div>
    
</div>
</div>
<p>Ahora, vamos a visualizar el ajuste para ambos modelos:</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>x_new <span class="op">=</span> np.linspace(x_1s[<span class="dv">0</span>].<span class="bu">min</span>(), x_1s[<span class="dv">0</span>].<span class="bu">max</span>(), <span class="dv">100</span>)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>posterior_l <span class="op">=</span> az.extract(idata_l)</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>posterior_p <span class="op">=</span> az.extract(idata_p)</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>α_l_post <span class="op">=</span> posterior_l[<span class="st">'α'</span>].mean().item()</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>β_l_post <span class="op">=</span> posterior_l[<span class="st">'β'</span>].mean().item()</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>y_l_post <span class="op">=</span> α_l_post <span class="op">+</span> β_l_post <span class="op">*</span>  x_new</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>plt.plot(x_new, y_l_post, <span class="st">'C0'</span>, label<span class="op">=</span><span class="st">'modelo lineal'</span>)</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>α_p_post <span class="op">=</span> posterior_p[<span class="st">'α'</span>].mean().item()</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>β_p_post <span class="op">=</span> posterior_p[<span class="st">'β'</span>].mean(<span class="st">"sample"</span>)</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>idx <span class="op">=</span> np.argsort(x_1s[<span class="dv">0</span>])</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>y_p_post <span class="op">=</span> α_p_post <span class="op">+</span> np.dot(β_p_post, x_1s)</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>plt.plot(x_1s[<span class="dv">0</span>][idx], y_p_post[idx], <span class="st">'C1'</span>, label<span class="op">=</span><span class="ss">f'polinomio de orden </span><span class="sc">{</span>order<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>plt.plot(x_1s[<span class="dv">0</span>], y_1s, <span class="st">"k."</span>)</span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>plt.legend()<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="07_Comparación_de_modelos_files/figure-html/cell-6-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>El modelo de orden 2 parece estar haciendo un mejor trabajo, pero el modelo lineal no es tan malo. Veamos un prueba predictiva a posteriori</p>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>_, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">4</span>), sharey<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>az.plot_ppc(idata_l, num_pp_samples<span class="op">=</span><span class="dv">100</span>, ax<span class="op">=</span>axes[<span class="dv">0</span>], legend<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_title(<span class="st">'modelo lineal'</span>)</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>az.plot_ppc(idata_p, num_pp_samples<span class="op">=</span><span class="dv">100</span>, ax<span class="op">=</span>axes[<span class="dv">1</span>])<span class="op">;</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_title(<span class="ss">f'polinomio de orden </span><span class="sc">{</span>order<span class="sc">}</span><span class="ss">'</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="07_Comparación_de_modelos_files/figure-html/cell-7-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>En vez de comparar directamente la distribución de datos observados versus la distribución predicha podemos comparar estadísticos sumarios.</p>
<p>En el panel superior de la siguiente figura se muestra 2 KDEs, representando la distribución de las medias predichas por los modelos. El punto sobre eje x indica el valor observado.</p>
<p>En el segundo panel lo mismo pero para el rango intercuartil.</p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">1</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">8</span>), sharey<span class="op">=</span><span class="st">"row"</span>)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>colors <span class="op">=</span> [<span class="st">"C0"</span>, <span class="st">"C1"</span>]</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>titles <span class="op">=</span> [<span class="st">"mediana"</span>, <span class="st">"rango intercuartil"</span>]</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>modelos <span class="op">=</span> [<span class="st">"lineal"</span>, <span class="ss">f'orden </span><span class="sc">{</span>order<span class="sc">}</span><span class="ss">'</span>]</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>idatas <span class="op">=</span> [idata_l, idata_p]</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> iqr(x, a<span class="op">=-</span><span class="dv">1</span>):</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.subtract(<span class="op">*</span>np.percentile(x, [<span class="dv">75</span>, <span class="dv">25</span>], axis<span class="op">=</span>a))</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idata, c <span class="kw">in</span> <span class="bu">zip</span>(idatas, colors):</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>    az.plot_bpv(idata, kind<span class="op">=</span><span class="st">"t_stat"</span>, t_stat<span class="op">=</span><span class="st">"mean"</span>, ax<span class="op">=</span>axes[<span class="dv">0</span>], color<span class="op">=</span>c)</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idata, c <span class="kw">in</span> <span class="bu">zip</span>(idatas, colors):</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>    az.plot_bpv(idata, kind<span class="op">=</span><span class="st">"t_stat"</span>, t_stat<span class="op">=</span>iqr, ax<span class="op">=</span>axes[<span class="dv">1</span>], color<span class="op">=</span>c)</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ax, title, <span class="kw">in</span> <span class="bu">zip</span>(axes, titles):</span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a>    ax.set_title(title)</span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> idx, (c, modelo) <span class="kw">in</span> <span class="bu">enumerate</span>(<span class="bu">zip</span>(colors, modelos)):</span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a>        ax.legend_.legendHandles[idx]._alpha <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a>        ax.legend_.legendHandles[idx]._color <span class="op">=</span> c</span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>        ax.legend_._loc <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a>        ax.legend_.texts[idx]._text <span class="op">=</span> modelo <span class="op">+</span> <span class="st">" "</span> <span class="op">+</span> ax.legend_.texts[idx]._text</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="07_Comparación_de_modelos_files/figure-html/cell-8-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>En la figura anterior también se incluyen unos valores llamados bpv, Bayesian p-value. Los bpv son una forma numérica de resumir una comparación entre datos simulados y datos reales. Para obtenerlos se elige un estadístico sumario, como por ejemplo la mediana, el cual es calculado tanto para los datos como para las simulaciones. Luego contamos la cantidad de veces que el estadístico predicho es igual o mayor al calculado a partir de los datos observados. Si los valores observado y concuerdan con los predichos, deberíamos esperar un <em>valor p</em> de 0.5. Es decir la mitad de las predicciones están por debajo y la mitad por encima de lo observado. Caso contrario, estamos en presencia de una distribución predictiva <em>a posteriori</em> sesgada.</p>
<p>Si estás familiarizado con los métodos frecuentistas es posible que ya conozcas el concepto de <em>valor p</em>. Además es posible que hayas escuchado que en estadística Bayesiana no se usan <em>valores p</em>. Por lo que este ejemplo puede generarte confusión. Veamos que está pasando. Estos bpv son efectivame <em>valores p</em> ya que se definen de como:</p>
<p><span class="math display">\[\text{Bayesian p-value } \triangleq p(T_{\mathcal{sim}} \le T_{\mathcal{obs}} ) \mid \hat y)\]</span></p>
<p>Es decir, queremos estimar la probabilidad de obtener un estadístico <span class="math inline">\(T_{sim}\)</span>, a partir de las simulaciones, que sea igual o menor que la de obtener un valor de estadísitco <span class="math inline">\(T_{obs}\)</span> a partir de los datos. En principio <span class="math inline">\(T\)</span> puede ser casi cualquier cantidad derivada de los datos. En la figura anterior <span class="math inline">\(T\)</span> es la mediana (panel superior) o el rango interquartil (panel inferior). En este ejemplo es razonable que la media <em>de bien</em> por que precisamente el modelo lineal está construido para capturar la media. Si en vez de graficar la media, evaluaramos la mediana, veriamos diferencias algo más grandes. En general un estadístico que sea <em>ortogonal</em> a lo que el modelo ajusta de forma directa será más informativo. Ante la duda puede ser conveniente evaluar más de un estadístico. En general es útil preguntarse que aspectos de los datos nos interesa capturar mejor.</p>
<p>Lo <strong>Bayesiano</strong> de estos <em>valores p</em> es que NO estamos usando una distribución de muestreo sino <em>la distribución predictiva a posteriori</em>. Además NO estamos asumiendo ninguna hipótesis nula para calcular el valor p.&nbsp;En cambio, estamos, permitiendo que los parámetros varíen de acuerdo con el modelo y los datos. Otra diferencia es que no estamos usando ningún método predefinido para declarar significación estadística, ni estamos realizando pruebas de hipótesis.</p>
<p>Otra forma de usar los bvp, es preguntarse para cada valor observado, cual es la probabilidad de predecir un valor menor o igual</p>
<p><span class="math display">\[p(\tilde y_i  \le y_i \mid y_i)\]</span></p>
<p>Si el modelo está bien calibrado la probabilidad debería ser la misma para todos los valores no importan si estos son altos, bajos, en las colas en el seno de la distribución etc. Es decir esperaríamos ver una distribución uniforme.</p>
<p>Siguiedo esta idea, en la siguiente figura se muestra una gráfica que muestra la distribuciónes para el modelo lineal y el de order 2. La linea blanca indica la distribución uniforme esperada y la banda gris indica las desviaciones esperadas dado el tamaño finito de la muestra observada.</p>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">3</span>))</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idata, c <span class="kw">in</span> <span class="bu">zip</span>(idatas, colors):</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>    az.plot_bpv(idata, color<span class="op">=</span>c, ax<span class="op">=</span>ax)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="07_Comparación_de_modelos_files/figure-html/cell-9-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>Las pruebas predictivas <em>a posteriori</em>, ya sea utilizando gráficos o resúmenes numéricos como los <em>valores p bayesianos</em>, o incluso una combinación de ambos son ideas muy flexibles. El concepto es lo suficientemente general para permitir que una analista use su imaginación para encontrar diferentes formas de explorar la distribución predictiva <em>a posteriori</em> y use las que mejor se ajusten a los fines de poder interpretar los datos y modelos.</p>
<p>En las siguientes secciones vamos a explorar otros métodos para comparar modelos.</p>
</section>
</section>
<section id="la-navaja-de-occam-simplicidad-y-exactitud" class="level1">
<h1>La navaja de Occam: simplicidad y exactitud</h1>
<p>Al elegir entre explicaciones alternativas, existe un principio conocido como la navaja de Occam que establece de manera general que si tenemos dos o más explicaciones equivalentes para el mismo fenómeno, debemos elegir la más simple.</p>
<p>Hay muchas justificaciones para esta heurística; una de ellas está relacionada con el criterio de falsabilidad introducido por Popper, otra tiene una perspectiva más pragmática y afirma que, dado que los modelos más simples son más fáciles de entender que los modelos más complejos, es conveniente quedarse con el más simple. Otra justificación se basa en propia estadísticas Bayesiana, como veremos cuando analicemos los Factores de Bayes. Sin entrar en los detalles de estas justificaciones, vamos a aceptar este criterio como una regla útil por el momento, simplemente algo que suena como una guía razonable.</p>
<p>Otro factor que generalmente debemos tener en cuenta al comparar modelos es su exactitud, es decir, qué tan bueno es un modelo ajustando los datos. Un cantidad comunmente usada en regresión es el coeficiente de determinación R², que podemos interpretar como la proporción de varianza explicada en una regresión lineal. En la sección anterior vimos algunos ejemplos de pruebas predictivas <em>a posteriori</em> a modo de evaluación de cual modelo ajusta mejor los datos. En definitiva, si tenemos dos (o más) modelos y uno de ellos explica los datos mejor que el otro, deberíamos preferir ese modelo, es decir, queremos el modelo con mayor exactitud ¿Verdad?</p>
<p>Intuitivamente, parece que al comparar modelos, tendemos a preferir aquellos que mejor ajusten los datos y aquellos que sean más simples. Hasta ahora todo bien, pero ¿Qué hacemos si el modelo más simple es el peor ajustando los datos? O de forma más general, ¿Cómo balancear ambas contribuciones?</p>
<section id="muchos-parámetros-pueden-conducir-a-sobreajuste" class="level2">
<h2 class="anchored" data-anchor-id="muchos-parámetros-pueden-conducir-a-sobreajuste">Muchos parámetros (pueden) conducir a sobreajuste</h2>
<p>Vamos a comenzar por combinar polinomios cada vez más complejos en un conjunto de datos muy simple. En lugar de utilizar la maquinaria Bayesiana, usaremos la aproximación de mínimos cuadrados para ajustar modelos lineales. Recuerde que este último se puede interpretar desde una perspectiva Bayesiana como un modelo con <em>a prioris</em> planos. Entonces, en cierto sentido, seguimos siendo Bayesianos solo que estamos tomando un atajo ;-)</p>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>_, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">1</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">4</span>))</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>x0 <span class="op">=</span> np.array([<span class="fl">4.</span>, <span class="fl">5.</span>, <span class="fl">6.</span>, <span class="fl">9.</span>, <span class="dv">12</span>, <span class="fl">14.</span>])</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>y0 <span class="op">=</span> np.array([<span class="fl">4.2</span>, <span class="fl">6.1</span>, <span class="fl">5.</span>, <span class="fl">10.</span>, <span class="dv">10</span>, <span class="fl">14.</span>])</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>order <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">5</span>]</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>ax.plot(x0, y0, <span class="st">'ko'</span>, zorder<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>ax.set_yticks([])</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>ax.set_xticks([])</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>x_n <span class="op">=</span> np.linspace(x0.<span class="bu">min</span>(), x0.<span class="bu">max</span>(), <span class="dv">100</span>)</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>ps <span class="op">=</span> []</span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> order:</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>    p <span class="op">=</span> np.polynomial.Polynomial.fit(x0, y0, deg<span class="op">=</span>i)</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>    ps.append(p)</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>    yhat <span class="op">=</span> p(x0)</span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>    ybar <span class="op">=</span> np.mean(y0)</span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a>    ss_regression <span class="op">=</span> np.<span class="bu">sum</span>((yhat<span class="op">-</span>y0)<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>    ss_total <span class="op">=</span> np.<span class="bu">sum</span>((ybar<span class="op">-</span>y0)<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a>    r2 <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> ss_regression <span class="op">/</span> ss_total</span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a>    ax.plot(x_n, p(x_n), label<span class="op">=</span><span class="ss">f'orden </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">, $R^2$= </span><span class="sc">{</span>r2<span class="sc">:.3f}</span><span class="ss">'</span>)</span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a>ax.legend(loc<span class="op">=</span><span class="dv">2</span>, fontsize<span class="op">=</span><span class="dv">12</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="07_Comparación_de_modelos_files/figure-html/cell-10-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>De la figura anterior podemos ver que el aumento de la complejidad del modelo se acompaña de una mayor exactitud reflejada en el coeficiente de determinación R². De hecho, podemos ver que el polinomio de orden 5 se ajusta perfectamente a los datos, obteniendo un R²=1.</p>
<p>¿Por qué el polinomio de grado 5 puede capturar los datos sin perder uno solo de ellos? La razón es que tenemos el mismo número de parámetros que de datos es decir 6. Por lo tanto, el modelo está actuando simplemente como una forma alternativa de expresar los datos. El modelo no está aprendiendo algo sobre los datos, ¡Está memorizando los datos! A partir de este simple ejemplo, podemos ver que un modelo con mayor ajuste no siempre es lo ideal.</p>
<p>Ahora agregaremos dos datos nuevos y sin volver a ajustar los modelos veremos como cambia el R². Se puede ver que al modelo lineal le va mejor en este caso que al polinomial.</p>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>_, ax <span class="op">=</span> plt.subplots( figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">4</span>))</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>x_ <span class="op">=</span> np.array([<span class="fl">6.5</span>, <span class="dv">10</span>])</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>y_ <span class="op">=</span> np.array([<span class="dv">7</span>, <span class="dv">10</span>])</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>ax.plot(x0, y0, <span class="st">'ko'</span>, zorder<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>ax.plot(x_, y_, <span class="st">'ks'</span>, zorder<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>ax.set_yticks([])</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>ax.set_xticks([])</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>x1 <span class="op">=</span> np.concatenate((x0, x_))</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>y1 <span class="op">=</span> np.concatenate((y0, y_))</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idx, i <span class="kw">in</span> <span class="bu">enumerate</span>(order):</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>    yhat <span class="op">=</span> ps[idx](x1)</span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>    ybar <span class="op">=</span> np.mean(y1)</span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>    ss_regression <span class="op">=</span> np.<span class="bu">sum</span>((yhat<span class="op">-</span>y1)<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>    ss_total <span class="op">=</span> np.<span class="bu">sum</span>((ybar<span class="op">-</span>y1)<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>    r2 <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> ss_regression <span class="op">/</span> ss_total</span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>    ax.plot(x_n, ps[idx](x_n), label<span class="op">=</span><span class="ss">f'orden </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">, $R^2$= </span><span class="sc">{</span>r2<span class="sc">:.3f}</span><span class="ss">'</span>)</span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a>ax.legend(loc<span class="op">=</span><span class="dv">2</span>, fontsize<span class="op">=</span><span class="dv">12</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="07_Comparación_de_modelos_files/figure-html/cell-11-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>Cuando un modelo ajusta muy bien, el conjunto de datos utilizado para aprender los parámetros de ese modelo, pero muy mal otros conjuntos de datos, decimos que tenemos sobreajuste (overfitting). Este es un problema muy común al analizar datos.</p>
<p>Una forma muy útil de pensar el sobreajuste es considerar que un conjunto de datos tiene dos componentes; la señal y el ruido. La señal es lo que queremos capturar (o aprender) de los datos. Si usamos un conjunto de datos es porque creemos que hay una señal allí, de lo contrario será un ejercicio fútil. El ruido, en cambio, no es útil y es el producto de los errores de medición, las limitaciones en la forma en que se generaron o capturaron los datos, la presencia de datos corruptos, etc. Un modelo sobreajusta cuando es tan flexible (para un conjunto de datos) que es capaz de <em>aprender</em> el ruido. Esto tiene como consecuencia que la señal queda oculta.</p>
<p>Esta es una justificación práctica para la navaja de Occam. Y nos advierte que al menos en principio, siempre es posible crear un modelo tan complejo que explique todos los detalles, incluso los más irrelevantes. Tal como en el Imperio descripto por Borges, donde los cartógrafos alcanzaron tal nivel de sofisticación que crearon un mapa del Imperio cuyo tamaño era el del propio Imperio, y que coincidía punto por punto con él.</p>
</section>
<section id="muy-pocos-parámetros-conducen-a-un-subajuste" class="level2">
<h2 class="anchored" data-anchor-id="muy-pocos-parámetros-conducen-a-un-subajuste">Muy pocos parámetros conducen a un subajuste</h2>
<p>Continuando con el mismo ejemplo pero en el otro extremo de complejidad, tenemos el modelo de orden 0. Este modelo es simplemente una Gaussiana disfrazada de modelo lineal. Este modelo solo es capaz de capturar el valor de la media de <span class="math inline">\(Y\)</span>, y es por lo tanto totalente indiferente a los valores de <span class="math inline">\(x\)</span>. Decimos que este modelo ha subajustado los datos.</p>
</section>
<section id="el-equilibrio-entre-simplicidad-y-exactitud" class="level2">
<h2 class="anchored" data-anchor-id="el-equilibrio-entre-simplicidad-y-exactitud">El equilibrio entre simplicidad y exactitud</h2>
<p><em>Todo debe hacerse tan simple como sea posible, pero no más simple</em> es una cita que a menudo se atribuye a Einstein y es similar a la navaja de Occam. Al igual que en una dieta saludable, al modelar tenemos que mantener un balance. Idealmente, nos gustaría tener un modelo que ni sub-ajuste ni sobre-ajuste los datos. De alguna forma hay que balancear simplicidad y bondad de ajuste.</p>
</section>
<section id="medidas-de-exactitud-predictiva" class="level2">
<h2 class="anchored" data-anchor-id="medidas-de-exactitud-predictiva">Medidas de exactitud predictiva</h2>
<p>En el ejemplo previo, es relativamente facil de ver que el modelo de orden 0 es <em>demasiado</em> simple mientras que el modelo de orde 5 es <em>demasiado</em> complejo. Pero que podemos decir de los otros dos modelos? Cómo podríamos establecer un ranking numérico de estos modelos? Para poder hacer esto necesitamos formalizar nuestra intuición sobre este balance entre simplicidad y exactitud</p>
<p>Veamos un par de términos que nos serán de utilidad.</p>
<ul>
<li><strong>Exactitud dentro de la muestra</strong> (within-sample accuracy). La exactitud medida con los mismos datos usado para ajustar el modelo.</li>
<li><strong>Exactitud fuera de la muestra</strong> (out-of-sample accuracy). La exactitud medida con datos no usados para ajustar el modelo.</li>
</ul>
<p>La exactitud dentro de la muestra será, en promedio, menor a la exactitud fuera de la muestra. Es por ello que usar la exactitud dentro de la muestra para evaluar un modelo en general conducirá a pensar que tenemos un mejor modelo de lo que realmente es. Utilizar la exactitud fuera de la muestra es por lo tanto una mejor idea para evitar engañarnos a nosotros mismos. Sin embargo, esta aproximación requiere dejar datos fuera del ajuste, lo cual es un lujo que en general no nos podemos dar. Ya que este es un problema central en el análisis de datos existen varias propuestas para abordarlo. Dos aproximaciones muy populares son:</p>
<ul>
<li><p>Validación cruzada: esta es una estrategia empírica basada en dividir los datos disponibles en subconjuntos separados que se utilizan para ajustar y evaluar de forma alternativa</p></li>
<li><p>Criterios de información: este es un término general usado para referirse a varias expresiones que aproximan la exactitud fuera de la muestra como la exactitud dentro de la muestra más un término que penaliza a modelos complejos.</p></li>
</ul>
<section id="validación-cruzada" class="level3">
<h3 class="anchored" data-anchor-id="validación-cruzada">Validación cruzada</h3>
<p>La validación cruzada es una solución simple y, en la mayoría de los casos, efectiva para comparar modelos. Tomamos nuestros datos y los dividimos en K porciones. Intentamos mantener las porciones más o menos iguales (en tamaño y, a veces, también en otras características, como, por ejemplo, un número igual de clases). Luego usamos K-1 porciones para entrenar el modelo y el resto para evaluarlo. Este proceso se repite sistemáticamente dejando, por cada iteración, una porción diferente fuera del conjunto de entrenamiento y usando esa porción como el conjunto de validación. Esto se repite hasta que hayamos completado K rondas de ajuste-evaluación. La exactitud del modelo será la del promedio a lo largo de las K rondas. Esto se conoce como validación cruzada K-fold. Cuando K es igual a la cantidad de puntos de datos, obtenemos lo que se conoce como <em>validación cruzada dejando un punto afuera</em> (LOOCV del inglés leave-one-out cross-validation). Por último una vez que hemos relizado la validación cruzada, usamos todos los datos para ajustar por última vez nuestro modelo y este es el modelo que se utiliza para hacer predicciones o para cualquier otro fin.</p>
<p><img src="img/cv.png" width="500"></p>
<p>La validación cruzada es una práctica estádard en en <em>machine learning</em>. Y apenas hemos descripto los aspectos más esenciales de esta práctica. Para mayor información pueden leer The Hundred-Page Machine Learning Book](http://themlbook.com/) o <a href="https://www.amazon.com/Python-Machine-Learning-scikit-learn-TensorFlow-ebook/dp/B0742K7HYF/ref=dp_ob_title_def">Python Machine Learning</a>, by Sebastian Raschka, o <a href="https://jakevdp.github.io/PythonDataScienceHandbook/">Python Data Science Handbook</a> by Jake Vanderplas.</p>
<p>La validación cruzada es una idea muy simple y útil, pero para algunos modelos o para grandes cantidades de datos, el costo computacional de la validación cruzada puede estar más allá de nuestras posibilidades. Muchas personas han tratado de encontrar cantidades más simples de calcular que se aproximen a los resultados obtenidos con la validación cruzada o que funcionen en escenarios donde la validación cruzada no puede ser tan fácil de realizar. Y ese es el tema de la siguiente sección.</p>
</section>
<section id="criterios-de-información" class="level3">
<h3 class="anchored" data-anchor-id="criterios-de-información">Criterios de información</h3>
<p>Los criterios de información son una colección de herramientas estrechamente relacionadas que se utilizan para comparar modelos en términos de la bondad del ajuste y de la complejidad del modelo. En otras palabras, los criterios de información formalizan la intuición que desarrollamos al comienzo del capítulo. La forma exacta en que se derivan estas cantidades tiene que ver con un campo conocido como <a href="http://www.inference.org.uk/mackay/itila/book.html">Teoría de la Información</a>.</p>
<section id="el-log-likelihood-y-la-deviance" class="level4">
<h4 class="anchored" data-anchor-id="el-log-likelihood-y-la-deviance">El log-likelihood y la <em>deviance</em></h4>
<p>Una forma intuitiva de medir qué tan bien un modelo se ajusta a los datos es calcular el error cuadrático medio entre los datos y las predicciones realizadas por el modelo:</p>
<p><span class="math display">\[\frac{1}{n} \sum_{i=1}^{n}  (y_i - \operatorname{E} (y_i \mid \theta))^2\]</span></p>
<p><span class="math inline">\(\operatorname{E} (y_i \mid \theta)\)</span> es el valor predicho dados los parámetros estimados. Es importante notar que esto es esencialmente el promedio entre la diferencia entre los datos observados y los predichos. Tomar el cuadrado de los errores asegura que las diferencias no se cancelen y enfatiza grandes errores comparado con otros alternativas como por ejemplo calcular el valor absoluto.</p>
<p>El error cuadrático medio, puede resultarnos familiar ya que es muy popular. Pero si nos detenemos a reflexionar sobre esta cantidad veremos que en principio no tiene nada de especial y bien podríamos idear otras expresiones similares. Cuando adoptamos una aproximación probabilista vemos que una expresión más general (y <em>natural</em>) es la siguiente:</p>
<p><span class="math display">\[ \sum_{i=1}^{n} \log p(y_i \mid \theta)\]</span></p>
<p>Esto es, la suma (sobre <span class="math inline">\(n\)</span> datos) de los <em>likelihoods</em> (en escala logarítmica). Esto es <em>natural</em> por que al elegir un likelihood en un modelo estamos eleigiendo implícitamente una métrica para evaluar el ajuste del modelo. Cuando <span class="math inline">\(p(y_i \mid \theta)\)</span> es una gaussiana entonces la suma de log-likelihood será proporcional al error cuadrático medio.</p>
<p>Cuando se discuten criterios de información y por razones puramente históricas suele ser común hablar de <em>deviance</em> que es simplemente:</p>
<p><span class="math display">\[-2\ \sum_{i=1}^{n} \log \ p(y_i \mid \theta)\]</span></p>
<p>Es decir el log-likelihood multiplicado por -2.</p>
<p>La <em>deviance</em> es usada en contextos Bayesianos y no Bayesianos, la diferencia es que bajo un marco Bayesiano <span class="math inline">\(\theta\)</span> representa una distribución de probabilidad y no una estimación puntual.</p>
<ul>
<li>Cuanto menor es la <em>deviance</em>, mayor es el likelihood y mayor es el acuerdo entre las predicciones del modelo y los datos. Es decir, a menor <em>deviance</em>, mejor ajuste</li>
<li>La <em>deviance</em> se calcula a partir de los datos usados para ajustar el modelo es por lo tanto una forma de estimar la exactitud dentro de la muestra. Como ya vimos esto significa que en promedio la <em>deviance</em> va a tender a elegir modelos más complejos, necesitamos por lo tanto algún criterio para balancear esa tendencia.</li>
</ul>
<p>En las siguientes secciones, aprenderemos sobre diferentes criterios de información. Los cuales tienen en común el uso de la <em>desviace</em> y un término de penalización. La diferencia radica en cómo se calculan cada uno de estos dos términos.</p>
</section>
<section id="criterio-de-información-de-akaike" class="level4">
<h4 class="anchored" data-anchor-id="criterio-de-información-de-akaike">Criterio de información de Akaike</h4>
<p>Este es un criterio de información muy conocido y ampliamente utilizado fuera del universo Bayesiano y se define como:</p>
<p><span class="math display">\[AIC = -2 \sum_{i=1}^{n} \log p(y_i \mid \hat{\theta}_{mle}) + 2 k \]</span></p>
<p>Donde, k es el número de parámetros del modelo y <span class="math inline">\(\hat{\theta}_{mle}\)</span> es la estimación por máxima verosimilitud para <span class="math inline">\(\theta\)</span>.</p>
<p>La estimación de máxima verosimilitud es una práctica común para los no-bayesianos y, en general, es equivalente a la estimación Bayesiana del máximo a posteriori (MAP) cuando se usan priors <em>planos</em>. Es importante notar que $_{mle} $ es una estimación puntual y no una distribución.</p>
<p>Acá vemos como el factor <span class="math inline">\(-2\)</span> aparece de nuevo, como ya dijimos esto tiene razones históricas y no es relevante ya que es una constante. Lo importante, desde el punto de vista práctico, es que el primer término toma en cuenta cuan bien el modelo ajusta los datos, mientras que el segundo término penaliza la complejidad del modelo. Por lo tanto si dos modelos ajustan los datos igualmente bien. AIC dice que deberemos elegir aquel modelo con el menor número de parámetros, lo cual nos recuerda a la navaja de Ocam.</p>
<p>AIC funciona bien en enfoques no-bayesianos, pero de lo contrario es problemático. Una de las razones es que no utiliza la distribución a posteriori y, por lo tanto, descarta información sobre la incertidumbre en la estimación. Además AIC asume que los priors son <em>planos</em> y, por lo tanto, AIC es incompatible con priors informativos y ligeramente informativos como los utilizados en este libro. Tampoco es buena idea usarlo con modelos jerárquicos por lo que ya dijimos. Además, la cantidad de parámetros de un modelo no es una buena medida de la complejidad del mismo cuando se usan priors informativos o estructuras como la jerárquica ya que estas son formas de <em>regularizar</em> el modelo que es una forma de reducir la <em>cantidad efectiva de parámetros</em>. Más adelante volveremos sobre esta idea de regularización.</p>
</section>
<section id="widely-applicable-information-criterion" class="level4">
<h4 class="anchored" data-anchor-id="widely-applicable-information-criterion">Widely applicable information criterion</h4>
<p>WAIC es algo así como la versión Bayesiana de AIC, al igual que este último WAIC se compone de dos términos uno que mide el ajuste y otro que penaliza. La siguiente expresión asume que la distribución a posteriori está representada como una muestra de tamaño S.</p>
<p><span class="math display">\[WAIC = -2 \sum_i^n \log \left(\frac{1}{S} \sum_{s=1}^S p(y_i \mid \theta^s) \right) + 2 \sum_i^n  \left( V_{s=1}^S \log p(y_i \mid \theta^s) \right)\]</span></p>
<p>El primer térino es similar al criterio de Akaike, solo que evaluado para todas las observaciones y todas las muestras del posterior. El segundo término es un poco más dificil de justificar sin entrar en tecnicismos. Pero es tabién una forma de penalizar la complejidad del modelo. Lo importante desde el punto de vista práctico es que WAIC usa todo el posterior (y no una estimación puntual) para el cálculo de ambos términos, por lo que WAIC puede ser aplicado virtualmente a cualquier modelo Bayesiano.</p>
</section>
<section id="validación-cruzada-de-dejando-uno-afuera-mediante-muestreo-de-importancia-usando-un-suavizado-de-pareto" class="level4">
<h4 class="anchored" data-anchor-id="validación-cruzada-de-dejando-uno-afuera-mediante-muestreo-de-importancia-usando-un-suavizado-de-pareto">Validación cruzada de dejando uno afuera mediante muestreo de importancia usando un suavizado de Pareto</h4>
<p>El problema clave con la validación cruzada dejando uno fuera es que es muy costosa ya que tenemos que reajustar el modelo tantas veces como datos tengamos. Por suerte, hay formas de evitar la fuerza bruta y aproximar la estimación ajustando una sola vez lo datos, y esto es lo que hace el método “muestreo de importancia usando un suavizado de Pareto”. El nombre es tan poco amigable que en la práctica le decimos LOO. Conceptualmente lo que estámos tratando de calcular es:</p>
<p><span class="math display">\[
\text{ELPD}_\text{LOO-CV} = \sum_{i=1}^{n} \log
    \int \ p(y_i \mid \theta) \; p(\theta \mid y_{-i}) d\theta
\]</span></p>
<p><span class="math display">\[
\sum_{i}^{n} \log
    \left( \frac{1}{s}\sum_j^s \mathbin{\color{#E9692C}{p(y_i \mid \theta_{-i}^j)}} \right)
\]</span></p>
<p>Es posible aproximar <span class="math inline">\(\color{#E9692C}{p(y_i \mid \theta_{-i}^j})\)</span> usando importance sampling, que es una forma de approximar una distribución repesando valores obtenidos de otra distribución. En nuestro caso la distribución conocida, una vez ajustado un modelo, es el log-likelihood. Y queremos aproximar el log-likelihood si hubieramos eliminado una observación. Para ello necesitamos estimar la “importancia” (o peso) que cada observación tiene en determinar la distribución a posteriori. Una distribución será más “importante” (o pesada) mientras más cambie el posterior al eliminar esa observación. Intuitivamente una observación relativamente poco probable es más importante que una relativamente esperada. Mientras mayor la sorpresa, mayor la importancia. Por suerte estos pesos se puede estimar sin necesidad de reajustar el modelo, de hecho el peso de la observación <span class="math inline">\(i\)</span> para la muestra del posterior <span class="math inline">\(s\)</span> es:</p>
<p><span class="math display">\[
w_s = \frac{1}{p(y_i \mid \theta_s)}
\]</span></p>
<p>El problema es que bajo ciertas condiciones estos pesos puede no ser confiables. El principal problema es que unos pocos <span class="math inline">\(w_s\)</span> podrían ser tan grandes que dominan el cálculo, y es aquí donde entra el suavizado de Pareto que basicamente consiste en reemplazar algunos de estos pesos por pesos obtenidos a partir de ajustar una distribución de Pareto ¿por qué una distribución de Pareto? Por que la teoría indica que los pesos debeŕian seguir esta distribución. Entonces para cada observation <span class="math inline">\(y_i\)</span> , los pesos más grandes se usan para estimar una distribución de Pareto y esa distribución se usa para reemplazar esos pesos por pesos “suavizados”. Este procedimiento le da robustes a la estimación del ELPD y además provee de un diagóstico ya que valores de <span class="math inline">\(k\)</span> (uno de los parámetros de la distribución de Pareto) mayores a 0.7 indican que posiblemente tengamos observaciones “muy influyentes”.</p>
</section>
<section id="otros-criterios-de-información" class="level4">
<h4 class="anchored" data-anchor-id="otros-criterios-de-información">Otros criterios de información</h4>
<p>Otro criterio de información muy usado es DIC, si usamos el <em>bayesómetero™</em> DIC, es más bayesiano que AIC pero menos que WAIC. Aunque aún es popular, WAIC y LOO han demostrado ser más útiles tanto teóricamente como empíricamente que DIC. Por lo cual NO recomendamos su uso.</p>
<p>Otro criterio muy usado es BIC (del inglés Bayesian Information Criteria), al igual que la regresión logística y la * sopa seca * de mi madre, este nombre puede ser engañoso. BIC se propuso como una forma de corregir algunos de los problemas con AIC y el autor propuso una justificación Bayesiana para ello. Pero BIC no es realmente Bayesiano en el sentido que al igual que AIC asume priors <em>planos</em> y utiliza una estimación por máxima verosimilitud.</p>
<p>Pero lo que es más importante, es que BIC difiere de AIC y WAIC en su objetivo. AIC y WAIC intentan reflejar cual modelo generaliza mejor a otros datos (exactitud predictiva) mientras que BIC intenta identificar cual es el modelo <em>correcto</em> y por lo tanto está más relacionado los factores de Bayes que con WAIC. Más adelante discutiremos Factores de Bayes y veremos como se diferenci de criterios como WAIC y LOO.</p>
</section>
</section>
</section>
<section id="calcular-los-criterios-de-información-con-arviz" class="level2">
<h2 class="anchored" data-anchor-id="calcular-los-criterios-de-información-con-arviz">Calcular los criterios de información con ArviZ</h2>
<p>Afortunadamente, calcular los criterios de información con ArviZ es muy simple. Veamos:</p>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>waic_l <span class="op">=</span> az.waic(idata_l)</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>waic_l</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">
<pre><code>Computed from 8000 posterior samples and 33 observations log-likelihood matrix.

          Estimate       SE
elpd_waic   -14.27     2.65
p_waic        2.36        -</code></pre>
</div>
</div>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>waic_p <span class="op">=</span> az.waic(idata_p)</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>waic_p</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="12">
<pre><code>Computed from 8000 posterior samples and 33 observations log-likelihood matrix.

          Estimate       SE
elpd_waic    -4.49     2.34
p_waic        2.61        -</code></pre>
</div>
</div>
<p>Lo mismo para LOO.</p>
<div class="cell" data-scrolled="true" data-execution_count="13">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>loo_l <span class="op">=</span> az.loo(idata_l)</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>loo_l</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<pre><code>Computed from 8000 posterior samples and 33 observations log-likelihood matrix.

         Estimate       SE
elpd_loo   -14.30     2.66
p_loo        2.39        -
------

Pareto k diagnostic values:
                         Count   Pct.
(-Inf, 0.5]   (good)       33  100.0%
 (0.5, 0.7]   (ok)          0    0.0%
   (0.7, 1]   (bad)         0    0.0%
   (1, Inf)   (very bad)    0    0.0%</code></pre>
</div>
</div>
<div class="cell" data-scrolled="true" data-execution_count="14">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>loo_p <span class="op">=</span> az.loo(idata_p)</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>loo_p</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>Computed from 8000 posterior samples and 33 observations log-likelihood matrix.

         Estimate       SE
elpd_loo    -4.52     2.35
p_loo        2.64        -
------

Pareto k diagnostic values:
                         Count   Pct.
(-Inf, 0.5]   (good)       33  100.0%
 (0.5, 0.7]   (ok)          0    0.0%
   (0.7, 1]   (bad)         0    0.0%
   (1, Inf)   (very bad)    0    0.0%</code></pre>
</div>
</div>
<p>Tanto <code>az.waic</code> como <code>az.loo</code> devuelven 3 valores</p>
<ol type="1">
<li>Una estimación puntual del ELPD.</li>
<li>El error estándar de esa estimación</li>
<li>El número efectivo de parámetros</li>
</ol>
<p>Además LOO devuelve un diagnóstico basado en el parámetro k, correspondiente al ajuste de la distribución de Pareto.</p>
<p>Los valores de WAIC o LOO no tienen sentido por si mismos, si no que deben ser interpretados de forma relativa. Es por ello que ArviZ ofrece dos funciones auxiliares para facilitar esta comparación veamos primero a <code>az.compare</code>.</p>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>cmp_df <span class="op">=</span> az.compare({<span class="st">'modelo_l'</span>:idata_l, <span class="st">'modelo_p'</span>:idata_p})</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>cmp_df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>rank</th>
      <th>elpd_loo</th>
      <th>p_loo</th>
      <th>elpd_diff</th>
      <th>weight</th>
      <th>se</th>
      <th>dse</th>
      <th>warning</th>
      <th>scale</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>modelo_p</th>
      <td>0</td>
      <td>-4.517563</td>
      <td>2.638813</td>
      <td>0.000000</td>
      <td>1.000000e+00</td>
      <td>2.345124</td>
      <td>0.000000</td>
      <td>False</td>
      <td>log</td>
    </tr>
    <tr>
      <th>modelo_l</th>
      <td>1</td>
      <td>-14.295518</td>
      <td>2.387078</td>
      <td>9.777955</td>
      <td>2.291500e-13</td>
      <td>2.657647</td>
      <td>2.684915</td>
      <td>False</td>
      <td>log</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<p>En las filas tenemos los modelos comparados y en la columnas tenemos</p>
<ul>
<li>rank : el orden de los modelos (de mejor a peor)</li>
<li>elpd : la estimación puntual del elpd usando</li>
<li>p : los parámetros efectivos</li>
<li>elpd_diff : la diferencia entre el ELPD del mejor modelo y los demás modelos</li>
<li>weight : el peso relativo de cada modelo. Si quisieramos hacer predicciones combinando los distintos modelos, en vez de elegir uno solo, este sería el peso que deberíamos asignar a cada modelo. En este caso vemos que el modelo polinomial se lleva todo el peso.</li>
<li>se : el error estándard del ELPD</li>
<li>dse : el error estándard de las difencias</li>
<li>warning : una advertencia sobre valores de k altos</li>
<li>scale : la escala en la que se calcula el ELPD</li>
</ul>
<p>También podemos obtener más o menos la misma información de forma gráfica usando la función <code>az.compareplot</code>.</p>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>az.plot_compare(cmp_df)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="07_Comparación_de_modelos_files/figure-html/cell-17-output-1.png" class="img-fluid"></p>
</div>
</div>
<ul>
<li>Los círculos vacíos representan los valores del ELPD y lineas negras el error estándar.</li>
<li>El valor más alto del ELPD se indica con una línea gris discontinua vertical para facilitar la comparación con otros valores.</li>
<li>Para todos los modelos, excepto <em>el mejor</em>, también obtenemos un triángulo que indica el valor de la diferencia del ELPD entre cada modelo y el <em>mejor</em> modelo. La barra de error gris que indica el error estándar de las diferencias entre las estimaciones puntuales.</li>
</ul>
<p>La forma más sencilla de utilizar los criterios de información es elegir un único modelo. Simplemente elija el modelo con el valor más alto de ELPD. Si seguimos esta regla tendremos que aceptar que el modelo cuadrático es el mejor. Incluso si tenemos en cuenta los errores estandar podemos ver que estos no se solapan. Lo que nos da cierta seguridad que efectivamente los modelos son <em>diferentes</em> entre si. Si, en cambio, los errores estándar se superpusieran, deberíamos proporcionar una respuesta más matizada.</p>
</section>
<section id="promedio-de-modelos" class="level2">
<h2 class="anchored" data-anchor-id="promedio-de-modelos">Promedio de modelos</h2>
<p>La selección de modelos es atractiva por su simplicidad, pero podríamos estar descartando información sobre la incertidumbre en nuestros modelos. Esto es de alguna manera similar a calcular el posterior completo y luego solo mantener la media del posterior; esto puede conducirnos a confiar <em>demasiado</em> en lo que creemos saber.</p>
<p>Una alternativa es seleccionar un solo modelo, pero informar y analizar los diferentes modelos junto con los valores de los criterios de información calculados, sus valores de error estándar y quizás también las pruebas predictivas a posteriori. Es importante poner todos estos números y pruebas en el contexto de nuestro problema para que nosotros y nuestra audiencia podamos tener una mejor idea de las posibles limitaciones y deficiencias de los modelos. Para quienes trabajan en el mundo académico, estos elementos se pueden utilizar para agregar elementos a la sección de discusión de un paper, presentación, tesis, etc. Y en la industria esto puede ser útil para informar a clientes sobre las ventajas y limitaciones de las predicciones o conclusiones del modelado.</p>
<p>Otra posibilidad es promediar los modelos. De esta forma estamos introduciendo la incertidumbre que tenemos sobre la bondad de cada modelo. De esta fora podemos generar un metamodelo (y meta-predicciones) usando un promedio pesado de cada modelo.</p>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>idata_w <span class="op">=</span> az.weight_predictions(idatas, weights<span class="op">=</span>[<span class="fl">0.35</span>, <span class="fl">0.65</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>_, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>az.plot_kde(idata_l.posterior_predictive[<span class="st">'y_pred'</span>].values, plot_kwargs<span class="op">=</span>{<span class="st">'color'</span>:<span class="st">'C0'</span>}, label<span class="op">=</span><span class="st">'modelo lineal'</span>, ax<span class="op">=</span>ax)</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>az.plot_kde(idata_p.posterior_predictive[<span class="st">'y_pred'</span>].values, plot_kwargs<span class="op">=</span>{<span class="st">'color'</span>:<span class="st">'C1'</span>}, label<span class="op">=</span><span class="st">'orden 2'</span>, ax<span class="op">=</span>ax)</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>az.plot_kde(idata_w.posterior_predictive[<span class="st">'y_pred'</span>].values, plot_kwargs<span class="op">=</span>{<span class="st">'color'</span>:<span class="st">'C2'</span>}, label<span class="op">=</span><span class="st">'modelo pesado'</span>, ax<span class="op">=</span>ax)</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>plt.plot(y_1s, np.zeros_like(y_1s), <span class="st">'k|'</span>, label<span class="op">=</span><span class="st">'observed data'</span>)</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>plt.yticks([])</span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>plt.legend()<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="07_Comparación_de_modelos_files/figure-html/cell-19-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>Hay otras formas de promediar modelos, como, por ejemplo, construir explícitamente un metamodelo que incluya todos los modelos de interés como casos particulares. Por ejemplo un polinomio de grado 2 contiene como caso particular un modelo lineal, o un modelo jerárquico es la versión continua entre dos extremos un modelo agrupado y uno desagrupado.</p>
</section>
<section id="factores-de-bayes" class="level2">
<h2 class="anchored" data-anchor-id="factores-de-bayes">Factores de Bayes</h2>
<p>Una alternativa LOO, validación cruzada y los criterios de información son los factores de Bayes. Es común que factores de Bayes aparezcan en la literatura como una alternativa Bayesiana al contraste de hipótesis frecuentista.</p>
<p>La “manera Bayesiana” de comparar modelos es calcular la <em>verosimilitud marginal</em> de cada modelo <span class="math inline">\(p(y \mid M_k)\)</span>, es decir, la probabilidad de los datos observados <span class="math inline">\(Y\)</span> dado el modelo <span class="math inline">\(M_k\)</span>. Esta cantidad, la <em>verosimilitud marginal</em>, es simplemente la constante de normalización del teorema de Bayes. Podemos ver esto si escribimos el teorema de Bayes y hacemos explícito el hecho de que todas las inferencias dependen del modelo.</p>
<p><span class="math display">\[p (\theta \mid Y, M_k ) = \frac{p(Y \mid \theta, M_k) p(\theta \mid M_k)}{p(Y \mid M_k)}\]</span></p>
<p>dónde:</p>
<ul>
<li><span class="math inline">\(y\)</span> son los datos</li>
<li><span class="math inline">\(\theta\)</span> los parámetros</li>
<li><span class="math inline">\(M_k\)</span> un modelo de k modelos competidores</li>
</ul>
<p>Si nuestro objetivo principal es elegir solo un modelo, el <em>mejor</em>, de un conjunto de modelos podemos elegir el que tiene el mayor valor de <span class="math inline">\(p(y \mid M_k)\)</span>. Esto está bien si asumimos que <strong>todos los modelos</strong> tienen la misma probabilidad <em>a priori</em>. De lo contrario debemos calcular:</p>
<p><span class="math display">\[p(M_k \mid y) \propto p(y \mid M_k) p(M_k)\]</span></p>
<p>Si en cambio, nuestro objetivo principal es comparar comparar modelos para determinar cuáles son más probables y en qué medida. Esto se puede lograr utilizando los factores de Bayes:</p>
<p><span class="math display">\[FB_{01} = \frac{p(y \mid M_0)}{p(y \mid M_1)}\]</span></p>
<p>es decir, el cociente entre la verosimilitud marginal de dos modelos. Cuanto mayor sea el FB, <em>mejor</em> el modelo en el numerador (<span class="math inline">\(M_0\)</span> en este ejemplo). Para facilitar la interpretación de los FB, Harold Jeffreys propuso una escala para la interpretación de los Factores de Bayes con niveles de <em>apoyo</em> o <em>fuerza</em>. Esta es solo una manera de poner números en palabras.</p>
<ul>
<li>1-3: anecdótico</li>
<li>3-10: moderado</li>
<li>10-30: fuerte</li>
<li>30-100: muy fuerte</li>
<li><span class="math inline">\(&gt;\)</span> 100: extremo</li>
</ul>
<p>Hay que tener en cuenta que si se obtiene números por debajo de 1, entonces el soporte es para el modelo en el denominador, también hay tablas disponibles para esos casos. O simplemente podemos tomar la inversa de los valores del valor obtenido.</p>
<p>Es muy importante recordar que estas reglas son solo convenciones, guías simples en el mejor de los casos. Los resultados siempre deben ponerse en el contexto de nuestros problemas y deben ir acompañados de suficientes detalles para que otros puedan evaluar por sí mismos si están de acuerdo con nuestras conclusiones. No es lo mismo la prueba necesaria para asegurar algo en física de partículas, o en un juzgado, o para decidir realziar una evacuación frente a una catástrofe natural que se avecina.</p>
</section>
<section id="algunas-observaciones" class="level2">
<h2 class="anchored" data-anchor-id="algunas-observaciones">Algunas observaciones</h2>
<p>Ahora discutiremos brevemente algunos hechos clave sobre la <em>verosimilitud marginal</em></p>
<ul>
<li>El bueno
<ul>
<li><strong>Navaja de Occam incluida</strong>: Los modelos con más parámetros tienen una penalización mayor que los modelos con menos parámetros. La razón intuitiva es que cuanto mayor es el número de parámetros, más se <em>extiende</em> el <em>prior</em> con respecto al likelihood.</li>
</ul></li>
<li>El malo
<ul>
<li>Para muchas problema la verosimilitud marginal no puede ser calculada analiticamente. Y aproximarla numéricamente suele ser una tarea difícil que suele requerir de métodos especializados. Esto se debe a que es necesario calcular una integral de una función altamente variable en un espacio de parámetros de gran dimensión.</li>
</ul></li>
</ul>
<p><span class="math display">\[p(y \mid M_k) = \int_{\theta_k} p(y \mid \theta_k, M_k) \; p(\theta_k | M_k) \; d\theta_k\]</span></p>
<ul>
<li>El feo
<ul>
<li>La probabilidad marginal depende <strong>sensiblemente</strong> de la distribución a prior para los parámetros en cada modelo <span class="math inline">\(p(\theta_k \mid M_k)\)</span>.</li>
</ul></li>
</ul>
<p>Es importante notar que <em>lo bueno</em> y <em>lo feo</em> están relacionados. Usar la verosimilitud marginal para comparar modelos es una buena idea porque ya incluye una penalización para modelos complejos (lo que nos ayuda a prevenir el sobreajuste) y, al mismo tiempo, un cambio en el prior afectará los cálculos de la verosimilitud marginal. Al principio esto suena un poco tonto; ya sabemos que los priors afectan los cálculos (de lo contrario, simplemente podríamos evitarlos), pero el punto aquí es la palabra <strong>sensiblemente</strong>. Estamos hablando que cambios en el posterior que apenas tendrían efecto en el posterior tendrán un gran impacto en el valor de la verosimilitud marginal.</p>
<p>El uso de los FB suele ser una divisoria de aguas entre Bayesianos. La dificultad de su cálculo y la sensibilidad a los priors son algunos de los argumentos. Otra razón es que al igual que lo p-valores y en general las pruebas de hipótesis los BF favorecen el pensamiento dicotómico por sobre la estimación del “tamaño del efecto”. Es decir en vez de hacernos preguntas del estilo ¿Cuantos años más de vida puede proporcionar, en promedio, un tratamiento oncológico? terminamos preguntando si la diferencia entre tratar y no tratar a un paciente es “estadísticamente significativa”. Ojo que esta última pregunta puede ser útil en algunos contextos, el punto es que en muchos otros contextos, ese tipo de preguntas no es la pregunta más relevante.</p>
</section>
<section id="cálculo-de-los-fb" class="level2">
<h2 class="anchored" data-anchor-id="cálculo-de-los-fb">Cálculo de los FB</h2>
<p>La verosimilitud marginal generalmente no está disponible en forma cerrada, excepto para algunos modelos. Por esta razón, se han ideado muchos métodos para calcular la probabilidad marginal. Algunos de estos métodos son tan simples e <a href="https://radfordneal.wordpress.com/2008/08/17/the-harmonic%20-mean-of-the-likelihood-worst-monte-carlo-method-ever/">ingenuos</a> que funciona muy mal en la práctica. La mayoría de los métodos útiles se han propuesto originalmente en el campo de la mecánica estadística. Esta conexión se explica porque la verosimilitud marginal es análoga a una cantidad central en física estadística conocida como <em>función de partición</em> que a su vez está estrechamente relacionada con otra cantidad muy importante, la <em>energía libre</em>. Muchas de las conexiones entre la mecánica estadística y la inferencia bayesiana se resumen <a href="https://arxiv.org/abs/1706.01428">aquí</a>.</p>
<section id="analiticamente" class="level3">
<h3 class="anchored" data-anchor-id="analiticamente">Analiticamente</h3>
<p>Para algunos modelos, como el modelo beta-binomial, podemos calcular la verosimilitud marginal analíticamente. Si escribimos este modelo como:</p>
<p><span class="math display">\[\theta \sim Beta(\alpha, \beta)\]</span> <span class="math display">\[y \sim Bin(n=1, p=\theta)\]</span></p>
<p>la <em>verosimilitud marginal</em> será:</p>
<p><span class="math display">\[p(y) = \binom {n}{h} \frac{B(\alpha + h,\ \beta + n - h)} {B(\alpha, \beta)}\]</span></p>
<p>dónde:</p>
<ul>
<li><span class="math inline">\(B\)</span> es la <a href="https://en.wikipedia.org/wiki/Beta_function">función beta</a> no confundirse con la distribución <span class="math inline">\(Beta\)</span></li>
<li><span class="math inline">\(n\)</span> es el número de intentos</li>
<li><span class="math inline">\(h\)</span> es el número de éxito</li>
</ul>
<p>Como solo nos importa el valor relativo de la <em>verosimilitud marginal</em> bajo dos modelos diferentes (para los mismos datos), podemos omitir el coeficiente binomial <span class="math inline">\(\binom {n}{h}\)</span>, por lo que podemos escribir:</p>
<p><span class="math display">\[p(y) \propto \frac{B(\alpha + h,\ \beta + n - h)} {B(\alpha, \beta)}\]</span></p>
<p>Esta expresión ha sido codificada en la siguiente celda, pero con un giro. Usaremos la función <code>betaln</code> en lugar de la función <code>beta</code>, esto se hace para evitar el overflow.</p>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> beta_binom(prior, y):</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Calcula la probabilidad marginal, analíticamente, para un modelo beta-binomial.</span></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a><span class="co">     prior : tupla</span></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a><span class="co">         tupla de parámetro alfa y beta para el prior (distribución beta)</span></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a><span class="co">     y : array</span></span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a><span class="co">         array con "1" y "0" correspondientes al éxito y falla respectivamente</span></span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>    alpha, beta <span class="op">=</span> prior</span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>    h <span class="op">=</span> np.<span class="bu">sum</span>(y)</span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a>    n <span class="op">=</span> <span class="bu">len</span>(y)</span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a>    p_y <span class="op">=</span> np.exp(betaln(alpha <span class="op">+</span> h, beta <span class="op">+</span> n <span class="op">-</span> h) <span class="op">-</span> betaln(alpha, beta))</span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> p_y</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Nuestros datos para este ejemplo consisten en 100 “lanzamientos de una moneda” y el mismo número de “caras” y cecas” observadas. Compararemos dos modelos uno con un prior uniforme y otro con un prior <em>más concentrado</em> alrededor de <span class="math inline">\(\theta = 0.5\)</span></p>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> np.repeat([<span class="dv">1</span>, <span class="dv">0</span>], [<span class="dv">50</span>, <span class="dv">50</span>])  <span class="co"># 50 "caras" y 50 "cecas"</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>priors <span class="op">=</span> ((<span class="dv">1</span>, <span class="dv">1</span>), (<span class="dv">30</span>, <span class="dv">30</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> a, b <span class="kw">in</span> priors:</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">300</span>)</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>    x_pdf <span class="op">=</span> pz.Beta(a, b).rv_frozen.pdf(x)</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>    plt.plot(x, x_pdf, label<span class="op">=</span><span class="vs">rf"$\alpha$ = </span><span class="sc">{</span>a<span class="sc">:d}</span><span class="vs">, $\beta$ = </span><span class="sc">{</span>b<span class="sc">:d}</span><span class="vs">"</span>)</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>    plt.yticks([])</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">"$</span><span class="ch">\\</span><span class="st">theta$"</span>)</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>    plt.legend()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="07_Comparación_de_modelos_files/figure-html/cell-22-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>La siguiente celda devuelve el factor de Bayes</p>
<div class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>BF <span class="op">=</span> beta_binom(priors[<span class="dv">1</span>], y) <span class="op">/</span> beta_binom(priors[<span class="dv">0</span>], y)</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">round</span>(BF))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>5</code></pre>
</div>
</div>
<p>Vemos que el modelo con el prior <span class="math inline">\(\text{beta}(30, 30)\)</span>, más concentrado, tiene <span class="math inline">\(\approx 5\)</span> veces más apoyo que el modelo con el $(1, 1). Esto es esperable ya que el prior para el primer caso se concentra alrededor de <span class="math inline">\(\theta = 0.5\)</span> y los datos <span class="math inline">\(Y\)</span> tienen el mismo número de caras y cruces, es decir acuerdan con un valor de <span class="math inline">\(\theta\)</span> alrededor de 0.5.</p>
</section>
<section id="sequential-monte-carlo" class="level3">
<h3 class="anchored" data-anchor-id="sequential-monte-carlo">Sequential Monte Carlo</h3>
<p>El método Sequential Monte Carlo es un método de meustreo que básicamente progresa mediante una serie de secuencias sucesivas desde el prior al posterior. Un subproducto de este proceso es la estimación de la verosimilitud marginal. En realidad, por razones numéricas, el valor devuelto es el logaritmo de la verosimilitud marginal.</p>
<div class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>models <span class="op">=</span> []</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>idatas <span class="op">=</span> []</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> alpha, beta <span class="kw">in</span> priors:</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> pm.Model() <span class="im">as</span> model:</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>        a <span class="op">=</span> pm.Beta(<span class="st">"a"</span>, alpha, beta)</span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a>        yl <span class="op">=</span> pm.Bernoulli(<span class="st">"yl"</span>, a, observed<span class="op">=</span>y)</span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>        idata <span class="op">=</span> pm.sample_smc(random_seed<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a>        models.append(model)</span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a>        idatas.append(idata)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Initializing SMC sampler...
Sampling 4 chains in 4 jobs</code></pre>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="100" class="" max="100" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [100/100 00:00&lt;?  Stage: 2 Beta: 1.000]
    </div>
    
</div>
<div class="cell-output cell-output-stdout">
<pre><code>    </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/osvaldo/proyectos/00_BM/arviz/arviz/data/base.py:221: UserWarning: More chains (4) than draws (3). Passed array should have shape (chains, draws, *shape)
  warnings.warn(
Initializing SMC sampler...
Sampling 4 chains in 4 jobs</code></pre>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="100" class="" max="100" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [100/100 00:00&lt;?  Stage: 0 Beta: 1.000]
    </div>
    
</div>
<div class="cell-output cell-output-stdout">
<pre><code>    </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/osvaldo/proyectos/00_BM/arviz/arviz/data/base.py:221: UserWarning: More chains (4) than draws (1). Passed array should have shape (chains, draws, *shape)
  warnings.warn(</code></pre>
</div>
</div>
<div class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>BF_smc <span class="op">=</span> np.exp(</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>    idatas[<span class="dv">1</span>].sample_stats[<span class="st">"log_marginal_likelihood"</span>].mean()</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>    <span class="op">-</span> idatas[<span class="dv">0</span>].sample_stats[<span class="st">"log_marginal_likelihood"</span>].mean()</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>np.<span class="bu">round</span>(BF_smc).item()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="24">
<pre><code>5.0</code></pre>
</div>
</div>
<p>Como podemos ver en la celda anterior, ¡SMC da esencialmente la misma respuesta que el cálculo analítico!</p>
<p>Nota: En la celda de arriba calculamos una diferencia (en lugar de una división) porque estamos en la escala logarítmica, por la misma razón tomamos la exponencial antes de devolver el resultado. Finalmente, la razón por la que calculamos la media es porque obtenemos un valor logarítmico de probabilidad marginal por cadena.</p>
<p>La ventaja de usar SMC para calcular la verosimilitud marginal es que podemos usarlo para una gama más amplia de modelos, ya que ya no necesitamos conocer una expresión en forma cerrada. El costo que pagamos por esta flexibilidad es un cálculo más costoso. Además hay que tener en cuenta que SMC (con un kernel Metropolis independiente implementado en PyMC) no es tan eficiente como NUTS. A medida que aumenta la dimensionalidad del problema, una estimación más precisa de la posterior y la <em>verosimilitud marginal</em> requerirá un mayor número de muestras del posterior.</p>
</section>
</section>
<section id="factores-de-bayes-e-inferencia" class="level2">
<h2 class="anchored" data-anchor-id="factores-de-bayes-e-inferencia">Factores de bayes e inferencia</h2>
<p>Hasta ahora hemos usado los factores de Bayes para juzgar qué modelo parece ser mejor para explicar los datos, y obtenemos que uno de los modelos es <span class="math inline">\(\approx 5\)</span> <em>mejor</em> que el otro.</p>
<p>Pero, ¿qué pasa con el posterior que obtenemos de estos modelos? ¿Qué tan diferentes son?</p>
<div class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>az.summary(idatas[<span class="dv">0</span>], var_names<span class="op">=</span><span class="st">"a"</span>, kind<span class="op">=</span><span class="st">"stats"</span>).<span class="bu">round</span>(<span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="25">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>mean</th>
      <th>sd</th>
      <th>hdi_3%</th>
      <th>hdi_97%</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>a</th>
      <td>0.5</td>
      <td>0.05</td>
      <td>0.4</td>
      <td>0.59</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>az.summary(idatas[<span class="dv">1</span>], var_names<span class="op">=</span><span class="st">"a"</span>, kind<span class="op">=</span><span class="st">"stats"</span>).<span class="bu">round</span>(<span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="26">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>mean</th>
      <th>sd</th>
      <th>hdi_3%</th>
      <th>hdi_97%</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>a</th>
      <td>0.5</td>
      <td>0.04</td>
      <td>0.42</td>
      <td>0.57</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<p>Podemos argumentar que los resultados son bastante similares, tenemos el mismo valor medio para <span class="math inline">\(\theta\)</span> y un posterior ligeramente más ancho para <code>model_0</code>, como se esperaba ya que este modelo tiene un prior más amplio. También podemos verificar la distribución predictiva posterior para ver qué tan similares son.</p>
<div class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>ppc_0 <span class="op">=</span> pm.sample_posterior_predictive(idatas[<span class="dv">0</span>], model<span class="op">=</span>models[<span class="dv">0</span>]).posterior_predictive</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>ppc_1 <span class="op">=</span> pm.sample_posterior_predictive(idatas[<span class="dv">1</span>], model<span class="op">=</span>models[<span class="dv">1</span>]).posterior_predictive</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Sampling: [yl]</code></pre>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="8000" class="" max="8000" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [8000/8000 00:00&lt;00:00]
    </div>
    
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Sampling: [yl]</code></pre>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="8000" class="" max="8000" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [8000/8000 00:00&lt;00:00]
    </div>
    
</div>
</div>
<div class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>_, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">9</span>, <span class="dv">6</span>))</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a>bins <span class="op">=</span> np.linspace(<span class="fl">0.2</span>, <span class="fl">0.8</span>, <span class="dv">8</span>)</span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> az.plot_dist(</span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a>    ppc_0[<span class="st">"yl"</span>].mean(<span class="st">"yl_dim_2"</span>),</span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a>    label<span class="op">=</span><span class="st">"model_0"</span>,</span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a>    kind<span class="op">=</span><span class="st">"hist"</span>,</span>
<span id="cb45-8"><a href="#cb45-8" aria-hidden="true" tabindex="-1"></a>    hist_kwargs<span class="op">=</span>{<span class="st">"alpha"</span>: <span class="fl">0.5</span>, <span class="st">"bins"</span>: bins},</span>
<span id="cb45-9"><a href="#cb45-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb45-10"><a href="#cb45-10" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> az.plot_dist(</span>
<span id="cb45-11"><a href="#cb45-11" aria-hidden="true" tabindex="-1"></a>    ppc_1[<span class="st">"yl"</span>].mean(<span class="st">"yl_dim_2"</span>),</span>
<span id="cb45-12"><a href="#cb45-12" aria-hidden="true" tabindex="-1"></a>    label<span class="op">=</span><span class="st">"model_1"</span>,</span>
<span id="cb45-13"><a href="#cb45-13" aria-hidden="true" tabindex="-1"></a>    color<span class="op">=</span><span class="st">"C1"</span>,</span>
<span id="cb45-14"><a href="#cb45-14" aria-hidden="true" tabindex="-1"></a>    kind<span class="op">=</span><span class="st">"hist"</span>,</span>
<span id="cb45-15"><a href="#cb45-15" aria-hidden="true" tabindex="-1"></a>    hist_kwargs<span class="op">=</span>{<span class="st">"alpha"</span>: <span class="fl">0.5</span>, <span class="st">"bins"</span>: bins},</span>
<span id="cb45-16"><a href="#cb45-16" aria-hidden="true" tabindex="-1"></a>    ax<span class="op">=</span>ax,</span>
<span id="cb45-17"><a href="#cb45-17" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb45-18"><a href="#cb45-18" aria-hidden="true" tabindex="-1"></a>ax.legend()</span>
<span id="cb45-19"><a href="#cb45-19" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">"$</span><span class="ch">\\</span><span class="st">theta$"</span>)</span>
<span id="cb45-20"><a href="#cb45-20" aria-hidden="true" tabindex="-1"></a>ax.xaxis.set_major_formatter(FormatStrFormatter(<span class="st">"</span><span class="sc">%0.1f</span><span class="st">"</span>))</span>
<span id="cb45-21"><a href="#cb45-21" aria-hidden="true" tabindex="-1"></a>ax.set_yticks([])<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="07_Comparación_de_modelos_files/figure-html/cell-29-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>En este ejemplo, los datos observados son más consistentes con el <code>modelo_1</code>, por que el prior se concentra en torno al valor correcto de <span class="math inline">\(\theta\)</span>, mientras que el <code>modelo_0</code>, asigna la misma probabilidad a todos los valores posibles de <span class="math inline">\(\theta\)</span>. Esta diferencia entre los modelos es capturada por el factor de Bayes. Podríamos decir que los factores de Bayes miden qué modelo, en su conjunto, es mejor para explicar los datos. Y esto incluye los detalles del prior, sin importar cuan similares son las predicciones de los modelos. En muchos escenarios lo que nos interesa al comparar modelos es cuan similares son las predicciones. Que es lo que estima LOO o validación cruzada.</p>
</section>
<section id="cociente-de-savage-dickey" class="level2">
<h2 class="anchored" data-anchor-id="cociente-de-savage-dickey">Cociente de Savage-Dickey</h2>
<p>Para los ejemplos anteriores hemos comparado dos modelos beta-binomiales, podríamos haber comparado dos modleos completamente diferentes. Pero hay veces que queremos comparar una hipótesis nula H_0 (o modelo nulo) contra una alternativa H_1. Por ejemplo, para responder a la pregunta <em>¿Está sesgada esta moneda?</em>, podríamos comparar el valor <span class="math inline">\(\theta = 0.5\)</span> (que representa el no-sesgo) con el resultado de un modelo en el que permitimos que <span class="math inline">\(\theta\)</span> varíe. Para este tipo de comparación, el modelo nulo está anidado dentro de la alternativa, lo que significa que el valor nulo es un valor particular del modelo que estamos construyendo. En esos casos, calcular el factor de Bayes es muy fácil y no requiere ningún método especial. Solo necesitamos comparar el prior y el posterior evaluados en el valor nulo (por ejemplo <span class="math inline">\(\theta = 0.5\)</span> ), bajo el modelo alternativo. Podemos ver que esto es cierto a partir de la siguiente expresión:</p>
<p><span class="math display">\[
BF_{01} = \frac{p(y \mid H_0)}{p(y \mid H_1)} \frac{p(\theta=0.5 \mid y, H_1)}{p(\theta=0.5 \mid H_1)}
\]</span></p>
<p>Que es cierta <a href="https://statproofbook.github.io/P/bf-sddr">solo</a> cuando H_0 es un caso particular de H_1.</p>
<p>Hagámoslo con PyMC y ArviZ. Solo necesitamos obtener muestras del prior y del posterior para un modelo. Probemos con el modelo beta-binomial con prior uniforme.</p>
<div class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> pm.Model() <span class="im">as</span> model_uni:</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>    a <span class="op">=</span> pm.Beta(<span class="st">"a"</span>, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>    yl <span class="op">=</span> pm.Bernoulli(<span class="st">"yl"</span>, a, observed<span class="op">=</span>y)</span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a>    idata_uni <span class="op">=</span> pm.sample(<span class="dv">2000</span>, random_seed<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a>    idata_uni.extend(pm.sample_prior_predictive(<span class="dv">8000</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [a]</code></pre>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="12000" class="" max="12000" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [12000/12000 00:03&lt;00:00 Sampling 4 chains, 0 divergences]
    </div>
    
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Sampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 4 seconds.
Sampling: [a, yl]</code></pre>
</div>
</div>
<p>Y ahora llamamos a la función de ArviZ <code>az.plot_bf</code></p>
<div class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>az.plot_bf(idata_uni, var_name<span class="op">=</span><span class="st">"a"</span>, ref_val<span class="op">=</span><span class="fl">0.5</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="07_Comparación_de_modelos_files/figure-html/cell-31-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>El gráfico muestra un KDE para el prior (azul) y otro para el posterior (turquesa). Los dos puntos negros muestran que evaluamos ambas distribuciones en el valor 0.5. Podemos ver que el factor de Bayes a favor de la hipótesis nula, BF_01, es <span class="math inline">\(\approx 8\)</span>, lo que podemos interpretar como una <em>evidencia moderada</em> a favor de la hipótesis nula (ver la escala de Jeffreys que discutimos antes).</p>
<p>Como ya comentamos, los factores de Bayes miden qué modelo, en su conjunto, es mejor para explicar los datos. Y esto incluye el prior, incluso si el prior tiene un impacto relativamente bajo en el cómputo del posterior. También podemos ver este efecto del prior al comparar un segundo modelo con el modelo nulo.</p>
<p>Si en cambio nuestro modelo fuera un beta-binomial con beta prior (30, 30), el BF_01 sería más bajo (<em>anecdótico</em> en la escala de Jeffrey). Esto se debe a que, según este modelo, el valor de <span class="math inline">\(\theta=0.5\)</span> es mucho más probable priori que para un prior uniforme y, por lo tanto, el posterior y el prior serán mucho más similares. Es decir, no hay demasiada <em>sorpresa</em> al ver la que el posterior se concentra alrededor de 0.5 después de recopilar datos.</p>
<p>Vamos a calcularlo para verlo por nosotros mismos.</p>
<div class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> pm.Model() <span class="im">as</span> model_conc:</span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>    a <span class="op">=</span> pm.Beta(<span class="st">"a"</span>, <span class="dv">30</span>, <span class="dv">30</span>)</span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a>    yl <span class="op">=</span> pm.Bernoulli(<span class="st">"yl"</span>, a, observed<span class="op">=</span>y)</span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a>    idata_conc <span class="op">=</span> pm.sample(<span class="dv">2000</span>, random_seed<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a>    idata_conc.extend(pm.sample_prior_predictive(<span class="dv">8000</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [a]</code></pre>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="12000" class="" max="12000" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [12000/12000 00:04&lt;00:00 Sampling 4 chains, 0 divergences]
    </div>
    
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Sampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 4 seconds.
Sampling: [a, yl]</code></pre>
</div>
</div>
<div class="cell" data-scrolled="true" data-execution_count="32">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>az.plot_bf(idata_conc, var_name<span class="op">=</span><span class="st">"a"</span>, ref_val<span class="op">=</span><span class="fl">0.5</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="07_Comparación_de_modelos_files/figure-html/cell-33-output-1.png" class="img-fluid"></p>
</div>
</div>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>